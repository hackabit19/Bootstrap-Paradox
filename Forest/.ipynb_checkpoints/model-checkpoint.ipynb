{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('forestfires.csv')\n",
    "#Getting Independent and Dependent Features\n",
    "X = dataset.iloc[:, 0:12].values # independent\n",
    "y = dataset.iloc[:, 12].values # dependent variable\n",
    "y = dataset.iloc[:, 12].values\n",
    "for i in range(0, len(y)):\n",
    "    y[i] = (y[i]*2.47)\n",
    "    if y[i] < 1.0:\n",
    "        y[i] = 1\n",
    "    elif y[i] < 10.0:\n",
    "        y[i] = 2\n",
    "    elif y[i] < 100.0:\n",
    "        y[i] = 3\n",
    "    elif y[i] < 300.0:\n",
    "        y[i] = 4\n",
    "    elif y[i] < 1000.0:\n",
    "        y[i] = 5\n",
    "    elif y[i] < 5000.0:\n",
    "        y[i] = 6\n",
    "    else:\n",
    "        y[i] = 7\n",
    "# Encoding categorical data for independent variables \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_1.fit_transform(X[:, 2]) #For month\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X_2.fit_transform(X[:, 3]) #For weekday\n",
    "onehotencoder = OneHotEncoder(categorical_features = [2])#dummy variable for month\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:] #avoid dummy variable trap \n",
    "onehotencoder = OneHotEncoder(categorical_features = [13])#dummy variable for week\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:] #avoid dummy variable trap\n",
    "'''Encoding For Classification'''\n",
    "from keras.utils import np_utils\n",
    "y = np_utils.to_categorical(y)\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "# Feature Scaling to optimize \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.379532</td>\n",
       "      <td>-0.451754</td>\n",
       "      <td>-0.482531</td>\n",
       "      <td>-0.371135</td>\n",
       "      <td>-0.375345</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>-0.743392</td>\n",
       "      <td>-0.121417</td>\n",
       "      <td>-0.194135</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985699</td>\n",
       "      <td>-0.274499</td>\n",
       "      <td>0.309337</td>\n",
       "      <td>0.081476</td>\n",
       "      <td>0.473402</td>\n",
       "      <td>0.644544</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>-0.626218</td>\n",
       "      <td>0.987112</td>\n",
       "      <td>-0.076682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.379532</td>\n",
       "      <td>-0.451754</td>\n",
       "      <td>-0.482531</td>\n",
       "      <td>-0.371135</td>\n",
       "      <td>2.664215</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>-0.743392</td>\n",
       "      <td>-0.121417</td>\n",
       "      <td>-0.194135</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.588128</td>\n",
       "      <td>-1.882556</td>\n",
       "      <td>0.072783</td>\n",
       "      <td>0.259419</td>\n",
       "      <td>0.572957</td>\n",
       "      <td>-0.453261</td>\n",
       "      <td>-0.028900</td>\n",
       "      <td>-0.265174</td>\n",
       "      <td>-1.019503</td>\n",
       "      <td>-0.076682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.379532</td>\n",
       "      <td>-0.451754</td>\n",
       "      <td>-0.482531</td>\n",
       "      <td>2.694439</td>\n",
       "      <td>-0.375345</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>-0.743392</td>\n",
       "      <td>-0.121417</td>\n",
       "      <td>-0.194135</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.301215</td>\n",
       "      <td>-1.078527</td>\n",
       "      <td>0.495200</td>\n",
       "      <td>-0.418604</td>\n",
       "      <td>-0.631417</td>\n",
       "      <td>0.158976</td>\n",
       "      <td>1.424129</td>\n",
       "      <td>-0.987262</td>\n",
       "      <td>-1.521157</td>\n",
       "      <td>-0.076682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.379532</td>\n",
       "      <td>-0.451754</td>\n",
       "      <td>-0.482531</td>\n",
       "      <td>-0.371135</td>\n",
       "      <td>-0.375345</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>-0.743392</td>\n",
       "      <td>-0.121417</td>\n",
       "      <td>-0.194135</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127757</td>\n",
       "      <td>-0.274499</td>\n",
       "      <td>0.461407</td>\n",
       "      <td>0.438895</td>\n",
       "      <td>0.659157</td>\n",
       "      <td>1.003442</td>\n",
       "      <td>1.493321</td>\n",
       "      <td>-0.866914</td>\n",
       "      <td>-1.521157</td>\n",
       "      <td>-0.076682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.634826</td>\n",
       "      <td>-0.451754</td>\n",
       "      <td>-0.482531</td>\n",
       "      <td>-0.371135</td>\n",
       "      <td>-0.375345</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>1.345185</td>\n",
       "      <td>-0.121417</td>\n",
       "      <td>-0.194135</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985699</td>\n",
       "      <td>-0.274499</td>\n",
       "      <td>0.157266</td>\n",
       "      <td>1.926865</td>\n",
       "      <td>0.726741</td>\n",
       "      <td>-0.347703</td>\n",
       "      <td>-0.219177</td>\n",
       "      <td>1.239177</td>\n",
       "      <td>-0.016195</td>\n",
       "      <td>-0.076682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>2.634826</td>\n",
       "      <td>-0.451754</td>\n",
       "      <td>-0.482531</td>\n",
       "      <td>-0.371135</td>\n",
       "      <td>-0.375345</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>1.345185</td>\n",
       "      <td>-0.121417</td>\n",
       "      <td>-0.194135</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.159157</td>\n",
       "      <td>-1.882556</td>\n",
       "      <td>0.089679</td>\n",
       "      <td>-0.144020</td>\n",
       "      <td>0.355231</td>\n",
       "      <td>-0.706601</td>\n",
       "      <td>0.714913</td>\n",
       "      <td>-0.806740</td>\n",
       "      <td>-0.517849</td>\n",
       "      <td>-0.076682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>-0.379532</td>\n",
       "      <td>-0.451754</td>\n",
       "      <td>-0.482531</td>\n",
       "      <td>-0.371135</td>\n",
       "      <td>-0.375345</td>\n",
       "      <td>2.895922</td>\n",
       "      <td>-0.743392</td>\n",
       "      <td>-0.121417</td>\n",
       "      <td>-0.194135</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556728</td>\n",
       "      <td>0.529530</td>\n",
       "      <td>0.478304</td>\n",
       "      <td>-1.461717</td>\n",
       "      <td>-2.115437</td>\n",
       "      <td>0.158976</td>\n",
       "      <td>-0.893798</td>\n",
       "      <td>-1.227958</td>\n",
       "      <td>0.987112</td>\n",
       "      <td>-0.076682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>-0.379532</td>\n",
       "      <td>-0.451754</td>\n",
       "      <td>2.072407</td>\n",
       "      <td>-0.371135</td>\n",
       "      <td>-0.375345</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>1.345185</td>\n",
       "      <td>-0.121417</td>\n",
       "      <td>-0.194135</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>...</td>\n",
       "      <td>1.414670</td>\n",
       "      <td>1.333558</td>\n",
       "      <td>-0.062391</td>\n",
       "      <td>-0.199244</td>\n",
       "      <td>0.324474</td>\n",
       "      <td>-0.601043</td>\n",
       "      <td>-0.478647</td>\n",
       "      <td>0.878133</td>\n",
       "      <td>-0.517849</td>\n",
       "      <td>-0.076682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>-0.379532</td>\n",
       "      <td>-0.451754</td>\n",
       "      <td>2.072407</td>\n",
       "      <td>-0.371135</td>\n",
       "      <td>-0.375345</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>-0.743392</td>\n",
       "      <td>-0.121417</td>\n",
       "      <td>-0.194135</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.588128</td>\n",
       "      <td>-0.274499</td>\n",
       "      <td>-0.163771</td>\n",
       "      <td>-0.437012</td>\n",
       "      <td>0.660776</td>\n",
       "      <td>-0.727713</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.456915</td>\n",
       "      <td>-1.019503</td>\n",
       "      <td>-0.076682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>-0.379532</td>\n",
       "      <td>-0.451754</td>\n",
       "      <td>-0.482531</td>\n",
       "      <td>-0.371135</td>\n",
       "      <td>2.664215</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>-0.743392</td>\n",
       "      <td>-0.121417</td>\n",
       "      <td>-0.194135</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.588128</td>\n",
       "      <td>-0.274499</td>\n",
       "      <td>0.072783</td>\n",
       "      <td>0.259419</td>\n",
       "      <td>0.572957</td>\n",
       "      <td>-0.453261</td>\n",
       "      <td>0.472741</td>\n",
       "      <td>-0.385522</td>\n",
       "      <td>-1.019503</td>\n",
       "      <td>-0.076682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.379532 -0.451754 -0.482531 -0.371135 -0.375345 -0.345313 -0.743392   \n",
       "1   -0.379532 -0.451754 -0.482531 -0.371135  2.664215 -0.345313 -0.743392   \n",
       "2   -0.379532 -0.451754 -0.482531  2.694439 -0.375345 -0.345313 -0.743392   \n",
       "3   -0.379532 -0.451754 -0.482531 -0.371135 -0.375345 -0.345313 -0.743392   \n",
       "4    2.634826 -0.451754 -0.482531 -0.371135 -0.375345 -0.345313  1.345185   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "99   2.634826 -0.451754 -0.482531 -0.371135 -0.375345 -0.345313  1.345185   \n",
       "100 -0.379532 -0.451754 -0.482531 -0.371135 -0.375345  2.895922 -0.743392   \n",
       "101 -0.379532 -0.451754  2.072407 -0.371135 -0.375345 -0.345313  1.345185   \n",
       "102 -0.379532 -0.451754  2.072407 -0.371135 -0.375345 -0.345313 -0.743392   \n",
       "103 -0.379532 -0.451754 -0.482531 -0.371135  2.664215 -0.345313 -0.743392   \n",
       "\n",
       "           7         8         9   ...        17        18        19  \\\n",
       "0   -0.121417 -0.194135 -0.069758  ...  0.985699 -0.274499  0.309337   \n",
       "1   -0.121417 -0.194135 -0.069758  ... -1.588128 -1.882556  0.072783   \n",
       "2   -0.121417 -0.194135 -0.069758  ... -0.301215 -1.078527  0.495200   \n",
       "3   -0.121417 -0.194135 -0.069758  ...  0.127757 -0.274499  0.461407   \n",
       "4   -0.121417 -0.194135 -0.069758  ...  0.985699 -0.274499  0.157266   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "99  -0.121417 -0.194135 -0.069758  ... -1.159157 -1.882556  0.089679   \n",
       "100 -0.121417 -0.194135 -0.069758  ...  0.556728  0.529530  0.478304   \n",
       "101 -0.121417 -0.194135 -0.069758  ...  1.414670  1.333558 -0.062391   \n",
       "102 -0.121417 -0.194135 -0.069758  ... -1.588128 -0.274499 -0.163771   \n",
       "103 -0.121417 -0.194135 -0.069758  ... -1.588128 -0.274499  0.072783   \n",
       "\n",
       "           20        21        22        23        24        25        26  \n",
       "0    0.081476  0.473402  0.644544  0.005696 -0.626218  0.987112 -0.076682  \n",
       "1    0.259419  0.572957 -0.453261 -0.028900 -0.265174 -1.019503 -0.076682  \n",
       "2   -0.418604 -0.631417  0.158976  1.424129 -0.987262 -1.521157 -0.076682  \n",
       "3    0.438895  0.659157  1.003442  1.493321 -0.866914 -1.521157 -0.076682  \n",
       "4    1.926865  0.726741 -0.347703 -0.219177  1.239177 -0.016195 -0.076682  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "99  -0.144020  0.355231 -0.706601  0.714913 -0.806740 -0.517849 -0.076682  \n",
       "100 -1.461717 -2.115437  0.158976 -0.893798 -1.227958  0.987112 -0.076682  \n",
       "101 -0.199244  0.324474 -0.601043 -0.478647  0.878133 -0.517849 -0.076682  \n",
       "102 -0.437012  0.660776 -0.727713  0.005696  0.456915 -1.019503 -0.076682  \n",
       "103  0.259419  0.572957 -0.453261  0.472741 -0.385522 -1.019503 -0.076682  \n",
       "\n",
       "[104 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential #For Initializing ANN\n",
    "from keras.layers import Dense #For Layers of ANN\n",
    "from keras.layers import Dropout\n",
    "# Initializing the ANN with sequence of layers (Could use a Graph)\n",
    "#Classifier Model\n",
    "classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 17, kernel_initializer = 'uniform', activation = 'relu', input_dim = 27))\n",
    "# Adding the hidden layers\n",
    "classifier.add(Dense(units = 17, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "classifier.add(Dense(units = 17, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# Adding the output layer\n",
    "# Probability for the outcome \n",
    "classifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "# Compiling the ANN\n",
    "#Another Option: categorical_crossentropy\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "413/413 [==============================] - 0s 792us/step - loss: 0.4086 - accuracy: 0.8571\n",
      "Epoch 2/300\n",
      "413/413 [==============================] - 0s 128us/step - loss: 0.4040 - accuracy: 0.8571\n",
      "Epoch 3/300\n",
      "413/413 [==============================] - 0s 125us/step - loss: 0.3933 - accuracy: 0.8571\n",
      "Epoch 4/300\n",
      "413/413 [==============================] - 0s 123us/step - loss: 0.3655 - accuracy: 0.8571\n",
      "Epoch 5/300\n",
      "413/413 [==============================] - 0s 128us/step - loss: 0.3187 - accuracy: 0.8568\n",
      "Epoch 6/300\n",
      "413/413 [==============================] - 0s 134us/step - loss: 0.2885 - accuracy: 0.8630\n",
      "Epoch 7/300\n",
      "413/413 [==============================] - 0s 128us/step - loss: 0.2831 - accuracy: 0.8634\n",
      "Epoch 8/300\n",
      "413/413 [==============================] - 0s 133us/step - loss: 0.2814 - accuracy: 0.8682\n",
      "Epoch 9/300\n",
      "413/413 [==============================] - 0s 203us/step - loss: 0.2799 - accuracy: 0.8686\n",
      "Epoch 10/300\n",
      "413/413 [==============================] - 0s 208us/step - loss: 0.2769 - accuracy: 0.8689\n",
      "Epoch 11/300\n",
      "413/413 [==============================] - 0s 207us/step - loss: 0.2760 - accuracy: 0.8706\n",
      "Epoch 12/300\n",
      "413/413 [==============================] - 0s 208us/step - loss: 0.2749 - accuracy: 0.8751\n",
      "Epoch 13/300\n",
      "413/413 [==============================] - 0s 205us/step - loss: 0.2750 - accuracy: 0.8706\n",
      "Epoch 14/300\n",
      "413/413 [==============================] - 0s 213us/step - loss: 0.2734 - accuracy: 0.8686\n",
      "Epoch 15/300\n",
      "413/413 [==============================] - 0s 208us/step - loss: 0.2733 - accuracy: 0.8710\n",
      "Epoch 16/300\n",
      "413/413 [==============================] - 0s 208us/step - loss: 0.2727 - accuracy: 0.8717\n",
      "Epoch 17/300\n",
      "413/413 [==============================] - 0s 210us/step - loss: 0.2720 - accuracy: 0.8724\n",
      "Epoch 18/300\n",
      "413/413 [==============================] - 0s 208us/step - loss: 0.2726 - accuracy: 0.8720\n",
      "Epoch 19/300\n",
      "413/413 [==============================] - 0s 210us/step - loss: 0.2717 - accuracy: 0.8717\n",
      "Epoch 20/300\n",
      "413/413 [==============================] - 0s 201us/step - loss: 0.2700 - accuracy: 0.8724\n",
      "Epoch 21/300\n",
      "413/413 [==============================] - 0s 212us/step - loss: 0.2710 - accuracy: 0.8731\n",
      "Epoch 22/300\n",
      "413/413 [==============================] - 0s 205us/step - loss: 0.2705 - accuracy: 0.8734\n",
      "Epoch 23/300\n",
      "413/413 [==============================] - 0s 220us/step - loss: 0.2695 - accuracy: 0.8751\n",
      "Epoch 24/300\n",
      "413/413 [==============================] - 0s 215us/step - loss: 0.2700 - accuracy: 0.8706\n",
      "Epoch 25/300\n",
      "413/413 [==============================] - 0s 210us/step - loss: 0.2703 - accuracy: 0.8717\n",
      "Epoch 26/300\n",
      "413/413 [==============================] - 0s 200us/step - loss: 0.2692 - accuracy: 0.8713\n",
      "Epoch 27/300\n",
      "413/413 [==============================] - 0s 208us/step - loss: 0.2691 - accuracy: 0.8734\n",
      "Epoch 28/300\n",
      "413/413 [==============================] - 0s 205us/step - loss: 0.2685 - accuracy: 0.8724\n",
      "Epoch 29/300\n",
      "413/413 [==============================] - 0s 200us/step - loss: 0.2688 - accuracy: 0.8741\n",
      "Epoch 30/300\n",
      "413/413 [==============================] - 0s 213us/step - loss: 0.2688 - accuracy: 0.8731\n",
      "Epoch 31/300\n",
      "413/413 [==============================] - 0s 215us/step - loss: 0.2672 - accuracy: 0.8741\n",
      "Epoch 32/300\n",
      "413/413 [==============================] - 0s 200us/step - loss: 0.2677 - accuracy: 0.8762\n",
      "Epoch 33/300\n",
      "413/413 [==============================] - 0s 188us/step - loss: 0.2685 - accuracy: 0.8689\n",
      "Epoch 34/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.2677 - accuracy: 0.8737\n",
      "Epoch 35/300\n",
      "413/413 [==============================] - 0s 200us/step - loss: 0.2682 - accuracy: 0.8741\n",
      "Epoch 36/300\n",
      "413/413 [==============================] - 0s 210us/step - loss: 0.2665 - accuracy: 0.8706\n",
      "Epoch 37/300\n",
      "413/413 [==============================] - 0s 215us/step - loss: 0.2668 - accuracy: 0.8755\n",
      "Epoch 38/300\n",
      "413/413 [==============================] - 0s 209us/step - loss: 0.2666 - accuracy: 0.8762\n",
      "Epoch 39/300\n",
      "413/413 [==============================] - 0s 209us/step - loss: 0.2651 - accuracy: 0.8737\n",
      "Epoch 40/300\n",
      "413/413 [==============================] - 0s 208us/step - loss: 0.2653 - accuracy: 0.8741\n",
      "Epoch 41/300\n",
      "413/413 [==============================] - 0s 216us/step - loss: 0.2655 - accuracy: 0.8731\n",
      "Epoch 42/300\n",
      "413/413 [==============================] - 0s 211us/step - loss: 0.2658 - accuracy: 0.8737\n",
      "Epoch 43/300\n",
      "413/413 [==============================] - 0s 210us/step - loss: 0.2643 - accuracy: 0.8751\n",
      "Epoch 44/300\n",
      "413/413 [==============================] - 0s 221us/step - loss: 0.2652 - accuracy: 0.8748\n",
      "Epoch 45/300\n",
      "413/413 [==============================] - 0s 208us/step - loss: 0.2639 - accuracy: 0.8765\n",
      "Epoch 46/300\n",
      "413/413 [==============================] - 0s 203us/step - loss: 0.2636 - accuracy: 0.8758\n",
      "Epoch 47/300\n",
      "413/413 [==============================] - 0s 225us/step - loss: 0.2645 - accuracy: 0.8762\n",
      "Epoch 48/300\n",
      "413/413 [==============================] - 0s 222us/step - loss: 0.2649 - accuracy: 0.8782\n",
      "Epoch 49/300\n",
      "413/413 [==============================] - 0s 203us/step - loss: 0.2634 - accuracy: 0.8744\n",
      "Epoch 50/300\n",
      "413/413 [==============================] - 0s 116us/step - loss: 0.2629 - accuracy: 0.8772\n",
      "Epoch 51/300\n",
      "413/413 [==============================] - 0s 87us/step - loss: 0.2625 - accuracy: 0.8755\n",
      "Epoch 52/300\n",
      "413/413 [==============================] - 0s 111us/step - loss: 0.2625 - accuracy: 0.8782\n",
      "Epoch 53/300\n",
      "413/413 [==============================] - 0s 119us/step - loss: 0.2616 - accuracy: 0.8779\n",
      "Epoch 54/300\n",
      "413/413 [==============================] - 0s 121us/step - loss: 0.2612 - accuracy: 0.8762\n",
      "Epoch 55/300\n",
      "413/413 [==============================] - 0s 119us/step - loss: 0.2615 - accuracy: 0.8769\n",
      "Epoch 56/300\n",
      "413/413 [==============================] - 0s 133us/step - loss: 0.2607 - accuracy: 0.8779\n",
      "Epoch 57/300\n",
      "413/413 [==============================] - 0s 210us/step - loss: 0.2607 - accuracy: 0.8769\n",
      "Epoch 58/300\n",
      "413/413 [==============================] - 0s 204us/step - loss: 0.2611 - accuracy: 0.8779\n",
      "Epoch 59/300\n",
      "413/413 [==============================] - 0s 203us/step - loss: 0.2612 - accuracy: 0.8758\n",
      "Epoch 60/300\n",
      "413/413 [==============================] - 0s 203us/step - loss: 0.2610 - accuracy: 0.8765\n",
      "Epoch 61/300\n",
      "413/413 [==============================] - 0s 198us/step - loss: 0.2599 - accuracy: 0.8782\n",
      "Epoch 62/300\n",
      "413/413 [==============================] - 0s 145us/step - loss: 0.2596 - accuracy: 0.8762\n",
      "Epoch 63/300\n",
      "413/413 [==============================] - 0s 77us/step - loss: 0.2589 - accuracy: 0.8762\n",
      "Epoch 64/300\n",
      "413/413 [==============================] - 0s 92us/step - loss: 0.2589 - accuracy: 0.8755\n",
      "Epoch 65/300\n",
      "413/413 [==============================] - 0s 116us/step - loss: 0.2587 - accuracy: 0.8779\n",
      "Epoch 66/300\n",
      "413/413 [==============================] - 0s 158us/step - loss: 0.2586 - accuracy: 0.8789\n",
      "Epoch 67/300\n",
      "413/413 [==============================] - 0s 205us/step - loss: 0.2579 - accuracy: 0.8765\n",
      "Epoch 68/300\n",
      "413/413 [==============================] - 0s 200us/step - loss: 0.2578 - accuracy: 0.8776\n",
      "Epoch 69/300\n",
      "413/413 [==============================] - 0s 201us/step - loss: 0.2559 - accuracy: 0.8762\n",
      "Epoch 70/300\n",
      "413/413 [==============================] - 0s 203us/step - loss: 0.2562 - accuracy: 0.8786\n",
      "Epoch 71/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.2559 - accuracy: 0.8782\n",
      "Epoch 72/300\n",
      "413/413 [==============================] - 0s 205us/step - loss: 0.2567 - accuracy: 0.8793\n",
      "Epoch 73/300\n",
      "413/413 [==============================] - 0s 205us/step - loss: 0.2550 - accuracy: 0.8800\n",
      "Epoch 74/300\n",
      "413/413 [==============================] - 0s 201us/step - loss: 0.2557 - accuracy: 0.8772\n",
      "Epoch 75/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.2539 - accuracy: 0.8789\n",
      "Epoch 76/300\n",
      "413/413 [==============================] - 0s 190us/step - loss: 0.2553 - accuracy: 0.8793\n",
      "Epoch 77/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.2552 - accuracy: 0.8789\n",
      "Epoch 78/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.2530 - accuracy: 0.8796\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 0s 82us/step - loss: 0.2521 - accuracy: 0.8786\n",
      "Epoch 80/300\n",
      "413/413 [==============================] - 0s 72us/step - loss: 0.2527 - accuracy: 0.8800\n",
      "Epoch 81/300\n",
      "413/413 [==============================] - 0s 131us/step - loss: 0.2518 - accuracy: 0.8817\n",
      "Epoch 82/300\n",
      "413/413 [==============================] - 0s 150us/step - loss: 0.2505 - accuracy: 0.8817\n",
      "Epoch 83/300\n",
      "413/413 [==============================] - 0s 154us/step - loss: 0.2509 - accuracy: 0.8800\n",
      "Epoch 84/300\n",
      "413/413 [==============================] - 0s 161us/step - loss: 0.2503 - accuracy: 0.8800\n",
      "Epoch 85/300\n",
      "413/413 [==============================] - 0s 153us/step - loss: 0.2512 - accuracy: 0.8800\n",
      "Epoch 86/300\n",
      "413/413 [==============================] - 0s 152us/step - loss: 0.2485 - accuracy: 0.8786\n",
      "Epoch 87/300\n",
      "413/413 [==============================] - 0s 148us/step - loss: 0.2484 - accuracy: 0.8814\n",
      "Epoch 88/300\n",
      "413/413 [==============================] - 0s 157us/step - loss: 0.2491 - accuracy: 0.8810\n",
      "Epoch 89/300\n",
      "413/413 [==============================] - 0s 189us/step - loss: 0.2495 - accuracy: 0.8796\n",
      "Epoch 90/300\n",
      "413/413 [==============================] - 0s 201us/step - loss: 0.2472 - accuracy: 0.8834\n",
      "Epoch 91/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.2476 - accuracy: 0.8820\n",
      "Epoch 92/300\n",
      "413/413 [==============================] - 0s 203us/step - loss: 0.2482 - accuracy: 0.8845\n",
      "Epoch 93/300\n",
      "413/413 [==============================] - 0s 197us/step - loss: 0.2461 - accuracy: 0.8859\n",
      "Epoch 94/300\n",
      "413/413 [==============================] - 0s 205us/step - loss: 0.2461 - accuracy: 0.8820\n",
      "Epoch 95/300\n",
      "413/413 [==============================] - 0s 198us/step - loss: 0.2456 - accuracy: 0.8820\n",
      "Epoch 96/300\n",
      "413/413 [==============================] - 0s 200us/step - loss: 0.2453 - accuracy: 0.8834\n",
      "Epoch 97/300\n",
      "413/413 [==============================] - 0s 205us/step - loss: 0.2464 - accuracy: 0.8810\n",
      "Epoch 98/300\n",
      "413/413 [==============================] - 0s 198us/step - loss: 0.2437 - accuracy: 0.8859\n",
      "Epoch 99/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.2419 - accuracy: 0.8845\n",
      "Epoch 100/300\n",
      "413/413 [==============================] - 0s 200us/step - loss: 0.2437 - accuracy: 0.8869\n",
      "Epoch 101/300\n",
      "413/413 [==============================] - 0s 210us/step - loss: 0.2430 - accuracy: 0.8838\n",
      "Epoch 102/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.2432 - accuracy: 0.8841\n",
      "Epoch 103/300\n",
      "413/413 [==============================] - 0s 188us/step - loss: 0.2429 - accuracy: 0.8845\n",
      "Epoch 104/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.2409 - accuracy: 0.8852\n",
      "Epoch 105/300\n",
      "413/413 [==============================] - 0s 188us/step - loss: 0.2415 - accuracy: 0.8852\n",
      "Epoch 106/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.2394 - accuracy: 0.8872\n",
      "Epoch 107/300\n",
      "413/413 [==============================] - 0s 197us/step - loss: 0.2409 - accuracy: 0.8859\n",
      "Epoch 108/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.2379 - accuracy: 0.8876\n",
      "Epoch 109/300\n",
      "413/413 [==============================] - 0s 205us/step - loss: 0.2392 - accuracy: 0.8865\n",
      "Epoch 110/300\n",
      "413/413 [==============================] - 0s 198us/step - loss: 0.2385 - accuracy: 0.8872\n",
      "Epoch 111/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.2378 - accuracy: 0.8879\n",
      "Epoch 112/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.2365 - accuracy: 0.8869\n",
      "Epoch 113/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.2393 - accuracy: 0.8845\n",
      "Epoch 114/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.2356 - accuracy: 0.8893\n",
      "Epoch 115/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.2347 - accuracy: 0.8872\n",
      "Epoch 116/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.2363 - accuracy: 0.8890\n",
      "Epoch 117/300\n",
      "413/413 [==============================] - 0s 176us/step - loss: 0.2378 - accuracy: 0.8845\n",
      "Epoch 118/300\n",
      "413/413 [==============================] - 0s 205us/step - loss: 0.2325 - accuracy: 0.8924\n",
      "Epoch 119/300\n",
      "413/413 [==============================] - 0s 178us/step - loss: 0.2366 - accuracy: 0.8900\n",
      "Epoch 120/300\n",
      "413/413 [==============================] - 0s 188us/step - loss: 0.2346 - accuracy: 0.8883\n",
      "Epoch 121/300\n",
      "413/413 [==============================] - 0s 185us/step - loss: 0.2366 - accuracy: 0.8893\n",
      "Epoch 122/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.2368 - accuracy: 0.8903\n",
      "Epoch 123/300\n",
      "413/413 [==============================] - 0s 188us/step - loss: 0.2314 - accuracy: 0.8907\n",
      "Epoch 124/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.2314 - accuracy: 0.8903\n",
      "Epoch 125/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.2290 - accuracy: 0.8931\n",
      "Epoch 126/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.2288 - accuracy: 0.8921\n",
      "Epoch 127/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.2293 - accuracy: 0.8910\n",
      "Epoch 128/300\n",
      "413/413 [==============================] - 0s 176us/step - loss: 0.2307 - accuracy: 0.8928\n",
      "Epoch 129/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.2281 - accuracy: 0.8924\n",
      "Epoch 130/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.2291 - accuracy: 0.8952\n",
      "Epoch 131/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.2284 - accuracy: 0.8935\n",
      "Epoch 132/300\n",
      "413/413 [==============================] - 0s 194us/step - loss: 0.2282 - accuracy: 0.8910\n",
      "Epoch 133/300\n",
      "413/413 [==============================] - 0s 178us/step - loss: 0.2272 - accuracy: 0.8935\n",
      "Epoch 134/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.2299 - accuracy: 0.8907\n",
      "Epoch 135/300\n",
      "413/413 [==============================] - 0s 180us/step - loss: 0.2267 - accuracy: 0.8948\n",
      "Epoch 136/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.2236 - accuracy: 0.8976\n",
      "Epoch 137/300\n",
      "413/413 [==============================] - 0s 176us/step - loss: 0.2260 - accuracy: 0.8928\n",
      "Epoch 138/300\n",
      "413/413 [==============================] - 0s 178us/step - loss: 0.2251 - accuracy: 0.8945\n",
      "Epoch 139/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.2249 - accuracy: 0.8952\n",
      "Epoch 140/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.2242 - accuracy: 0.8948\n",
      "Epoch 141/300\n",
      "413/413 [==============================] - 0s 182us/step - loss: 0.2254 - accuracy: 0.8935\n",
      "Epoch 142/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.2259 - accuracy: 0.8952\n",
      "Epoch 143/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.2268 - accuracy: 0.8948\n",
      "Epoch 144/300\n",
      "413/413 [==============================] - 0s 180us/step - loss: 0.2224 - accuracy: 0.8962\n",
      "Epoch 145/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.2220 - accuracy: 0.8952\n",
      "Epoch 146/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.2189 - accuracy: 0.8990\n",
      "Epoch 147/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.2216 - accuracy: 0.8948\n",
      "Epoch 148/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.2198 - accuracy: 0.8976\n",
      "Epoch 149/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.2193 - accuracy: 0.8983\n",
      "Epoch 150/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.2211 - accuracy: 0.8966\n",
      "Epoch 151/300\n",
      "413/413 [==============================] - 0s 201us/step - loss: 0.2220 - accuracy: 0.8976\n",
      "Epoch 152/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.2196 - accuracy: 0.8980\n",
      "Epoch 153/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.2144 - accuracy: 0.9014\n",
      "Epoch 154/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.2223 - accuracy: 0.8948\n",
      "Epoch 155/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.2162 - accuracy: 0.8997\n",
      "Epoch 156/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.2180 - accuracy: 0.8948\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 0s 181us/step - loss: 0.2137 - accuracy: 0.8990\n",
      "Epoch 158/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.2162 - accuracy: 0.9018\n",
      "Epoch 159/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.2180 - accuracy: 0.9007\n",
      "Epoch 160/300\n",
      "413/413 [==============================] - 0s 199us/step - loss: 0.2118 - accuracy: 0.8983\n",
      "Epoch 161/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.2181 - accuracy: 0.8993\n",
      "Epoch 162/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.2115 - accuracy: 0.9038\n",
      "Epoch 163/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.2082 - accuracy: 0.9066\n",
      "Epoch 164/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.2097 - accuracy: 0.9035\n",
      "Epoch 165/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.2111 - accuracy: 0.9007\n",
      "Epoch 166/300\n",
      "413/413 [==============================] - 0s 198us/step - loss: 0.2115 - accuracy: 0.9025\n",
      "Epoch 167/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.2122 - accuracy: 0.9031\n",
      "Epoch 168/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.2097 - accuracy: 0.9056\n",
      "Epoch 169/300\n",
      "413/413 [==============================] - 0s 173us/step - loss: 0.2075 - accuracy: 0.9042\n",
      "Epoch 170/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.2066 - accuracy: 0.9045\n",
      "Epoch 171/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.2101 - accuracy: 0.9028\n",
      "Epoch 172/300\n",
      "413/413 [==============================] - 0s 182us/step - loss: 0.2110 - accuracy: 0.9025\n",
      "Epoch 173/300\n",
      "413/413 [==============================] - 0s 222us/step - loss: 0.2066 - accuracy: 0.9076\n",
      "Epoch 174/300\n",
      "413/413 [==============================] - 0s 201us/step - loss: 0.2076 - accuracy: 0.9063\n",
      "Epoch 175/300\n",
      "413/413 [==============================] - 0s 195us/step - loss: 0.2102 - accuracy: 0.9014\n",
      "Epoch 176/300\n",
      "413/413 [==============================] - 0s 198us/step - loss: 0.2086 - accuracy: 0.9025\n",
      "Epoch 177/300\n",
      "413/413 [==============================] - 0s 197us/step - loss: 0.2039 - accuracy: 0.9063\n",
      "Epoch 178/300\n",
      "413/413 [==============================] - 0s 198us/step - loss: 0.2031 - accuracy: 0.9056\n",
      "Epoch 179/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.2045 - accuracy: 0.9056\n",
      "Epoch 180/300\n",
      "413/413 [==============================] - 0s 202us/step - loss: 0.2037 - accuracy: 0.9066\n",
      "Epoch 181/300\n",
      "413/413 [==============================] - 0s 200us/step - loss: 0.2037 - accuracy: 0.9083\n",
      "Epoch 182/300\n",
      "413/413 [==============================] - 0s 195us/step - loss: 0.2051 - accuracy: 0.9073\n",
      "Epoch 183/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.2048 - accuracy: 0.9066\n",
      "Epoch 184/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.2041 - accuracy: 0.9063\n",
      "Epoch 185/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.2018 - accuracy: 0.9087\n",
      "Epoch 186/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.1994 - accuracy: 0.9083\n",
      "Epoch 187/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.2050 - accuracy: 0.9083\n",
      "Epoch 188/300\n",
      "413/413 [==============================] - 0s 185us/step - loss: 0.2018 - accuracy: 0.9070\n",
      "Epoch 189/300\n",
      "413/413 [==============================] - 0s 198us/step - loss: 0.2004 - accuracy: 0.9080\n",
      "Epoch 190/300\n",
      "413/413 [==============================] - 0s 195us/step - loss: 0.2025 - accuracy: 0.9090\n",
      "Epoch 191/300\n",
      "413/413 [==============================] - 0s 198us/step - loss: 0.1982 - accuracy: 0.9121\n",
      "Epoch 192/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.2005 - accuracy: 0.9094\n",
      "Epoch 193/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1980 - accuracy: 0.9094\n",
      "Epoch 194/300\n",
      "413/413 [==============================] - 0s 192us/step - loss: 0.2030 - accuracy: 0.9066\n",
      "Epoch 195/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.2007 - accuracy: 0.9094\n",
      "Epoch 196/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.1987 - accuracy: 0.9045\n",
      "Epoch 197/300\n",
      "413/413 [==============================] - 0s 176us/step - loss: 0.2013 - accuracy: 0.9118\n",
      "Epoch 198/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.1995 - accuracy: 0.9108\n",
      "Epoch 199/300\n",
      "413/413 [==============================] - 0s 188us/step - loss: 0.1905 - accuracy: 0.9139\n",
      "Epoch 200/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.1953 - accuracy: 0.9125\n",
      "Epoch 201/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.1970 - accuracy: 0.9121\n",
      "Epoch 202/300\n",
      "413/413 [==============================] - 0s 178us/step - loss: 0.1954 - accuracy: 0.9135\n",
      "Epoch 203/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1983 - accuracy: 0.9094\n",
      "Epoch 204/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.1885 - accuracy: 0.9121\n",
      "Epoch 205/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.1946 - accuracy: 0.9101\n",
      "Epoch 206/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.1958 - accuracy: 0.9097\n",
      "Epoch 207/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1924 - accuracy: 0.9114\n",
      "Epoch 208/300\n",
      "413/413 [==============================] - 0s 180us/step - loss: 0.1955 - accuracy: 0.9121\n",
      "Epoch 209/300\n",
      "413/413 [==============================] - 0s 189us/step - loss: 0.1944 - accuracy: 0.9094\n",
      "Epoch 210/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.1905 - accuracy: 0.9121\n",
      "Epoch 211/300\n",
      "413/413 [==============================] - 0s 184us/step - loss: 0.1925 - accuracy: 0.9114\n",
      "Epoch 212/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.1922 - accuracy: 0.9146\n",
      "Epoch 213/300\n",
      "413/413 [==============================] - 0s 171us/step - loss: 0.1918 - accuracy: 0.9142\n",
      "Epoch 214/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.1958 - accuracy: 0.9101\n",
      "Epoch 215/300\n",
      "413/413 [==============================] - 0s 176us/step - loss: 0.1918 - accuracy: 0.9097\n",
      "Epoch 216/300\n",
      "413/413 [==============================] - 0s 203us/step - loss: 0.1892 - accuracy: 0.9132\n",
      "Epoch 217/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.1897 - accuracy: 0.9097\n",
      "Epoch 218/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1967 - accuracy: 0.9139\n",
      "Epoch 219/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1878 - accuracy: 0.9118\n",
      "Epoch 220/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.1879 - accuracy: 0.9114\n",
      "Epoch 221/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1858 - accuracy: 0.9153\n",
      "Epoch 222/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.1912 - accuracy: 0.9128\n",
      "Epoch 223/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.1892 - accuracy: 0.9128\n",
      "Epoch 224/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.1869 - accuracy: 0.9149\n",
      "Epoch 225/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.1894 - accuracy: 0.9135\n",
      "Epoch 226/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.1872 - accuracy: 0.9128\n",
      "Epoch 227/300\n",
      "413/413 [==============================] - 0s 176us/step - loss: 0.1844 - accuracy: 0.9125\n",
      "Epoch 228/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.1860 - accuracy: 0.9125\n",
      "Epoch 229/300\n",
      "413/413 [==============================] - 0s 187us/step - loss: 0.1850 - accuracy: 0.9142\n",
      "Epoch 230/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.1870 - accuracy: 0.9128\n",
      "Epoch 231/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1899 - accuracy: 0.9114\n",
      "Epoch 232/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.1837 - accuracy: 0.9149\n",
      "Epoch 233/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.1844 - accuracy: 0.9142\n",
      "Epoch 234/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.1817 - accuracy: 0.9153\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 0s 176us/step - loss: 0.1851 - accuracy: 0.9163\n",
      "Epoch 236/300\n",
      "413/413 [==============================] - 0s 180us/step - loss: 0.1866 - accuracy: 0.9156\n",
      "Epoch 237/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1811 - accuracy: 0.9135\n",
      "Epoch 238/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.1827 - accuracy: 0.9153\n",
      "Epoch 239/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1849 - accuracy: 0.9153\n",
      "Epoch 240/300\n",
      "413/413 [==============================] - 0s 175us/step - loss: 0.1837 - accuracy: 0.9146\n",
      "Epoch 241/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.1857 - accuracy: 0.9125\n",
      "Epoch 242/300\n",
      "413/413 [==============================] - 0s 188us/step - loss: 0.1850 - accuracy: 0.9184\n",
      "Epoch 243/300\n",
      "413/413 [==============================] - 0s 201us/step - loss: 0.1823 - accuracy: 0.9184\n",
      "Epoch 244/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.1820 - accuracy: 0.9132\n",
      "Epoch 245/300\n",
      "413/413 [==============================] - 0s 195us/step - loss: 0.1758 - accuracy: 0.9180\n",
      "Epoch 246/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1782 - accuracy: 0.9222\n",
      "Epoch 247/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.1809 - accuracy: 0.9177\n",
      "Epoch 248/300\n",
      "413/413 [==============================] - 0s 188us/step - loss: 0.1753 - accuracy: 0.9194\n",
      "Epoch 249/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1802 - accuracy: 0.9139\n",
      "Epoch 250/300\n",
      "413/413 [==============================] - 0s 175us/step - loss: 0.1785 - accuracy: 0.9170\n",
      "Epoch 251/300\n",
      "413/413 [==============================] - 0s 200us/step - loss: 0.1719 - accuracy: 0.9211\n",
      "Epoch 252/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1735 - accuracy: 0.9198\n",
      "Epoch 253/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1951 - accuracy: 0.9173\n",
      "Epoch 254/300\n",
      "413/413 [==============================] - 0s 176us/step - loss: 0.1794 - accuracy: 0.9173\n",
      "Epoch 255/300\n",
      "413/413 [==============================] - 0s 183us/step - loss: 0.1768 - accuracy: 0.9187\n",
      "Epoch 256/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1754 - accuracy: 0.9194\n",
      "Epoch 257/300\n",
      "413/413 [==============================] - 0s 203us/step - loss: 0.1757 - accuracy: 0.9180\n",
      "Epoch 258/300\n",
      "413/413 [==============================] - 0s 186us/step - loss: 0.1761 - accuracy: 0.9194\n",
      "Epoch 259/300\n",
      "413/413 [==============================] - 0s 208us/step - loss: 0.1789 - accuracy: 0.9153\n",
      "Epoch 260/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.1789 - accuracy: 0.9180\n",
      "Epoch 261/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1810 - accuracy: 0.9173\n",
      "Epoch 262/300\n",
      "413/413 [==============================] - 0s 203us/step - loss: 0.1775 - accuracy: 0.9201\n",
      "Epoch 263/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1817 - accuracy: 0.9177\n",
      "Epoch 264/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1745 - accuracy: 0.9211\n",
      "Epoch 265/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1760 - accuracy: 0.9201\n",
      "Epoch 266/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.1773 - accuracy: 0.9194\n",
      "Epoch 267/300\n",
      "413/413 [==============================] - 0s 195us/step - loss: 0.1777 - accuracy: 0.9187\n",
      "Epoch 268/300\n",
      "413/413 [==============================] - 0s 201us/step - loss: 0.1758 - accuracy: 0.9166\n",
      "Epoch 269/300\n",
      "413/413 [==============================] - 0s 180us/step - loss: 0.1723 - accuracy: 0.9211\n",
      "Epoch 270/300\n",
      "413/413 [==============================] - 0s 176us/step - loss: 0.1687 - accuracy: 0.9198\n",
      "Epoch 271/300\n",
      "413/413 [==============================] - 0s 179us/step - loss: 0.1723 - accuracy: 0.9215\n",
      "Epoch 272/300\n",
      "413/413 [==============================] - 0s 175us/step - loss: 0.1770 - accuracy: 0.9201\n",
      "Epoch 273/300\n",
      "413/413 [==============================] - 0s 185us/step - loss: 0.1759 - accuracy: 0.9177\n",
      "Epoch 274/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1776 - accuracy: 0.9201\n",
      "Epoch 275/300\n",
      "413/413 [==============================] - 0s 180us/step - loss: 0.1721 - accuracy: 0.9194\n",
      "Epoch 276/300\n",
      "413/413 [==============================] - 0s 188us/step - loss: 0.1751 - accuracy: 0.9218\n",
      "Epoch 277/300\n",
      "413/413 [==============================] - 0s 190us/step - loss: 0.1704 - accuracy: 0.9222\n",
      "Epoch 278/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.1704 - accuracy: 0.9215\n",
      "Epoch 279/300\n",
      "413/413 [==============================] - 0s 202us/step - loss: 0.1762 - accuracy: 0.9215\n",
      "Epoch 280/300\n",
      "413/413 [==============================] - 0s 203us/step - loss: 0.1732 - accuracy: 0.9229\n",
      "Epoch 281/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1749 - accuracy: 0.9211\n",
      "Epoch 282/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1745 - accuracy: 0.9225\n",
      "Epoch 283/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1739 - accuracy: 0.9198\n",
      "Epoch 284/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1718 - accuracy: 0.9184\n",
      "Epoch 285/300\n",
      "413/413 [==============================] - 0s 199us/step - loss: 0.1750 - accuracy: 0.9211\n",
      "Epoch 286/300\n",
      "413/413 [==============================] - 0s 206us/step - loss: 0.1660 - accuracy: 0.9215\n",
      "Epoch 287/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.1669 - accuracy: 0.9204\n",
      "Epoch 288/300\n",
      "413/413 [==============================] - 0s 191us/step - loss: 0.1752 - accuracy: 0.9198\n",
      "Epoch 289/300\n",
      "413/413 [==============================] - 0s 196us/step - loss: 0.1721 - accuracy: 0.9208\n",
      "Epoch 290/300\n",
      "413/413 [==============================] - 0s 198us/step - loss: 0.1731 - accuracy: 0.9222\n",
      "Epoch 291/300\n",
      "413/413 [==============================] - 0s 175us/step - loss: 0.1651 - accuracy: 0.9249\n",
      "Epoch 292/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1686 - accuracy: 0.9218\n",
      "Epoch 293/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1683 - accuracy: 0.9222\n",
      "Epoch 294/300\n",
      "413/413 [==============================] - 0s 181us/step - loss: 0.1695 - accuracy: 0.9215\n",
      "Epoch 295/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1656 - accuracy: 0.9249\n",
      "Epoch 296/300\n",
      "413/413 [==============================] - 0s 215us/step - loss: 0.1673 - accuracy: 0.9239\n",
      "Epoch 297/300\n",
      "413/413 [==============================] - 0s 212us/step - loss: 0.1656 - accuracy: 0.9229\n",
      "Epoch 298/300\n",
      "413/413 [==============================] - 0s 193us/step - loss: 0.1663 - accuracy: 0.9201\n",
      "Epoch 299/300\n",
      "413/413 [==============================] - 0s 205us/step - loss: 0.1689 - accuracy: 0.9211\n",
      "Epoch 300/300\n",
      "413/413 [==============================] - 0s 199us/step - loss: 0.1689 - accuracy: 0.9239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x241239af6c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size = 25, epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.93021464e-04, 1.94431413e-02, 1.70563638e-01, 1.56048372e-01,\n",
       "        5.24936318e-01, 8.55502784e-02, 4.32653241e-02],\n",
       "       [5.62534750e-16, 4.52157021e-01, 5.52654527e-02, 4.92577523e-01,\n",
       "        3.73230509e-11, 3.13472122e-14, 5.24723731e-14],\n",
       "       [1.29072640e-23, 9.91947591e-01, 1.08904333e-03, 6.96332986e-03,\n",
       "        6.68750564e-21, 3.15451770e-24, 3.77563818e-23],\n",
       "       [5.92761262e-09, 1.21160038e-01, 1.84140131e-01, 6.94616139e-01,\n",
       "        8.21299109e-05, 9.12609835e-07, 6.24280744e-07],\n",
       "       [2.12279772e-07, 7.59692252e-01, 1.61919087e-01, 7.83849508e-02,\n",
       "        1.69529869e-06, 5.10652740e-07, 1.22358642e-06],\n",
       "       [2.54825864e-04, 3.03022683e-01, 4.52832460e-01, 2.23208055e-01,\n",
       "        1.06536597e-02, 4.74490784e-03, 5.28342975e-03],\n",
       "       [1.41099834e-08, 2.79994369e-01, 1.69301644e-01, 5.50692737e-01,\n",
       "        1.08980857e-05, 1.92607047e-07, 1.85242158e-07],\n",
       "       [1.83951602e-14, 7.72634864e-01, 6.44196346e-02, 1.62945494e-01,\n",
       "        4.83049364e-11, 2.85436469e-13, 7.92544199e-13],\n",
       "       [5.40180963e-06, 2.51133054e-01, 3.25277537e-01, 4.22041416e-01,\n",
       "        1.31371943e-03, 1.19474484e-04, 1.09456785e-04],\n",
       "       [5.71640658e-06, 3.18771690e-01, 4.17300403e-01, 2.62355268e-01,\n",
       "        1.09327119e-03, 2.16280940e-04, 2.57317704e-04],\n",
       "       [5.55962776e-10, 7.59744942e-01, 1.04127370e-01, 1.36127800e-01,\n",
       "        2.97050970e-08, 1.36305944e-09, 3.15246629e-09],\n",
       "       [3.14055663e-17, 9.35743034e-01, 8.29624943e-03, 5.59606627e-02,\n",
       "        4.59106553e-15, 7.85506840e-18, 3.50425240e-17],\n",
       "       [2.00887589e-05, 3.58641356e-01, 3.85819525e-01, 2.53537208e-01,\n",
       "        1.29967637e-03, 3.09480587e-04, 3.72676470e-04],\n",
       "       [8.81123530e-09, 2.07278859e-02, 1.96937874e-01, 7.73540258e-01,\n",
       "        8.70572310e-03, 6.40915605e-05, 2.41446996e-05],\n",
       "       [1.23051692e-07, 6.88412547e-01, 1.96279570e-01, 1.15303569e-01,\n",
       "        2.65598419e-06, 5.11460257e-07, 1.09679581e-06],\n",
       "       [6.21841825e-13, 7.50362337e-01, 4.59102914e-02, 2.03727439e-01,\n",
       "        1.51594223e-10, 8.93659007e-13, 2.01914180e-12],\n",
       "       [6.37032645e-05, 3.19673985e-01, 4.23888534e-01, 2.50251949e-01,\n",
       "        3.73619492e-03, 1.11293583e-03, 1.27273996e-03],\n",
       "       [7.62151764e-09, 7.79998183e-01, 1.34462208e-01, 8.55393782e-02,\n",
       "        1.57192090e-07, 2.16372271e-08, 5.66220280e-08],\n",
       "       [2.04194308e-07, 5.17832279e-01, 2.39691496e-01, 2.42456734e-01,\n",
       "        1.55843954e-05, 1.52107486e-06, 2.28725480e-06],\n",
       "       [2.95379898e-09, 8.75279605e-01, 8.09592381e-02, 4.37611416e-02,\n",
       "        1.80034672e-08, 3.36205197e-09, 1.12095657e-08],\n",
       "       [4.20124930e-19, 8.15396011e-01, 1.48761896e-02, 1.69727772e-01,\n",
       "        5.33092129e-15, 2.18826971e-18, 7.21942807e-18],\n",
       "       [1.68876599e-12, 9.69361007e-01, 1.90374926e-02, 1.16014881e-02,\n",
       "        4.74089778e-12, 4.51080091e-13, 2.77477759e-12],\n",
       "       [2.68519285e-26, 4.46451720e-09, 2.15367654e-05, 9.99804914e-01,\n",
       "        1.73587570e-04, 7.94134317e-14, 2.49756558e-16],\n",
       "       [1.92288692e-08, 8.21425378e-01, 1.16659045e-01, 6.19152747e-02,\n",
       "        1.56991831e-07, 3.37849393e-08, 9.51232408e-08],\n",
       "       [1.64702446e-10, 4.12706733e-01, 1.05103657e-01, 4.82189476e-01,\n",
       "        1.26554298e-07, 1.03997522e-09, 1.29567790e-09],\n",
       "       [1.44340694e-21, 9.95790958e-01, 7.95161643e-04, 3.41394381e-03,\n",
       "        2.04430095e-20, 3.22341566e-23, 4.46100514e-22],\n",
       "       [2.56705536e-18, 8.14789176e-01, 1.64370444e-02, 1.68773830e-01,\n",
       "        1.68468534e-14, 9.68803942e-18, 3.07283337e-17],\n",
       "       [4.06956673e-03, 4.22484539e-02, 1.91490099e-01, 1.07648581e-01,\n",
       "        3.65325630e-01, 1.70946345e-01, 1.18271336e-01],\n",
       "       [4.27418323e-10, 7.67115355e-01, 9.92594361e-02, 1.33625269e-01,\n",
       "        2.14413163e-08, 9.32264932e-10, 2.19525353e-09],\n",
       "       [6.28387664e-24, 1.44729346e-01, 7.92257488e-03, 8.47348094e-01,\n",
       "        5.60900983e-16, 3.33119082e-21, 4.52652780e-21],\n",
       "       [3.81868065e-10, 8.21233749e-01, 8.86632577e-02, 9.01030153e-02,\n",
       "        1.12135048e-08, 6.91950053e-10, 1.89837035e-09],\n",
       "       [1.31733148e-04, 3.32452059e-01, 4.35802460e-01, 2.21447602e-01,\n",
       "        5.42859593e-03, 2.18075025e-03, 2.55679898e-03],\n",
       "       [9.68187327e-30, 8.73017882e-07, 4.54790752e-05, 9.99953628e-01,\n",
       "        1.94936341e-11, 1.94270669e-20, 4.86811189e-22],\n",
       "       [3.37284756e-09, 4.27917764e-02, 1.67213365e-01, 7.89418280e-01,\n",
       "        5.71112789e-04, 3.67969665e-06, 1.78456992e-06],\n",
       "       [1.49649515e-09, 8.55739295e-01, 8.82062390e-02, 5.60544468e-02,\n",
       "        1.61360134e-08, 2.09007478e-09, 6.63312871e-09],\n",
       "       [4.01687291e-15, 9.91325915e-01, 5.26037486e-03, 3.41367582e-03,\n",
       "        5.07513089e-15, 3.02277366e-16, 3.11095720e-15],\n",
       "       [1.94545138e-16, 9.94944632e-01, 2.98217614e-03, 2.07328168e-03,\n",
       "        2.06232909e-16, 8.93376899e-18, 1.15206156e-16],\n",
       "       [9.68187327e-30, 8.73017882e-07, 4.54790752e-05, 9.99953628e-01,\n",
       "        1.94936341e-11, 1.94270669e-20, 4.86811189e-22],\n",
       "       [7.58495433e-10, 5.83288729e-01, 1.29666522e-01, 2.87044615e-01,\n",
       "        1.57540114e-07, 3.64520769e-09, 5.95167426e-09],\n",
       "       [1.92829946e-17, 9.95459855e-01, 2.41430500e-03, 2.12579919e-03,\n",
       "        3.21542806e-17, 7.83397529e-19, 1.07922155e-17],\n",
       "       [1.66379399e-09, 6.16302641e-05, 7.16851698e-03, 7.57488608e-02,\n",
       "        9.15256321e-01, 1.59169082e-03, 1.73069857e-04],\n",
       "       [1.06999870e-07, 4.65773717e-02, 2.18616799e-01, 7.29157984e-01,\n",
       "        5.52835828e-03, 8.13956649e-05, 3.80319725e-05],\n",
       "       [4.55462779e-10, 8.81270170e-01, 7.22609237e-02, 4.64689098e-02,\n",
       "        4.57851312e-09, 5.34844335e-10, 1.86687910e-09],\n",
       "       [8.04041618e-22, 9.32266414e-01, 3.00738844e-03, 6.47260919e-02,\n",
       "        1.97023503e-18, 2.94940855e-22, 1.51766448e-21],\n",
       "       [1.78747281e-10, 3.94073486e-01, 1.07621782e-01, 4.98304725e-01,\n",
       "        1.60884071e-07, 1.30574984e-09, 1.58032809e-09],\n",
       "       [1.55799654e-16, 9.94571149e-01, 3.11930827e-03, 2.30953563e-03,\n",
       "        2.05302443e-16, 7.73160921e-18, 9.76555071e-17],\n",
       "       [2.80064711e-07, 1.24831749e-02, 2.28188872e-01, 5.36164284e-01,\n",
       "        2.18044996e-01, 3.83348553e-03, 1.28492888e-03],\n",
       "       [5.29160330e-20, 9.74800169e-01, 3.12919123e-03, 2.20705960e-02,\n",
       "        9.91972279e-18, 9.33350214e-21, 6.48009414e-20],\n",
       "       [8.34254195e-08, 7.49771416e-01, 1.61751553e-01, 8.84751156e-02,\n",
       "        1.03148136e-06, 2.28004453e-07, 5.44807904e-07],\n",
       "       [3.40284919e-03, 3.94011736e-02, 1.87586263e-01, 1.08921252e-01,\n",
       "        3.81248653e-01, 1.66723847e-01, 1.12715997e-01],\n",
       "       [2.41436676e-10, 8.48549008e-01, 9.06372890e-02, 6.08137660e-02,\n",
       "        7.38401384e-09, 6.84573398e-10, 2.20734453e-09],\n",
       "       [9.22589825e-05, 1.59487098e-01, 4.83522624e-01, 3.03672433e-01,\n",
       "        3.67818475e-02, 8.86753574e-03, 7.57624628e-03],\n",
       "       [9.21414195e-11, 9.22298074e-01, 4.79934178e-02, 2.97084861e-02,\n",
       "        5.74130798e-10, 6.63414115e-11, 2.77675993e-10],\n",
       "       [3.89741940e-19, 9.84206796e-01, 3.11452243e-03, 1.26787191e-02,\n",
       "        1.97489206e-17, 4.57331229e-20, 3.70618351e-19],\n",
       "       [4.07635063e-08, 4.18200523e-01, 2.50644416e-01, 3.31137776e-01,\n",
       "        1.53293749e-05, 8.33527508e-07, 1.08605957e-06],\n",
       "       [1.07514956e-13, 9.17650342e-01, 3.02944575e-02, 5.20551950e-02,\n",
       "        7.41408757e-12, 1.19098131e-13, 4.74188288e-13],\n",
       "       [1.46624423e-12, 2.45907739e-01, 9.79453921e-02, 6.56146824e-01,\n",
       "        3.92270643e-08, 9.94462568e-11, 1.06148715e-10],\n",
       "       [2.01646984e-03, 1.41448706e-01, 4.00498748e-01, 1.98454797e-01,\n",
       "        1.30576134e-01, 6.81169108e-02, 5.88882901e-02],\n",
       "       [1.30147764e-13, 8.51998389e-01, 3.27964723e-02, 1.15205169e-01,\n",
       "        1.67367422e-11, 1.18331031e-13, 3.48081590e-13],\n",
       "       [3.42833539e-10, 7.43339241e-01, 1.25569761e-01, 1.31090939e-01,\n",
       "        3.92818897e-08, 2.02476302e-09, 4.78691486e-09],\n",
       "       [4.29338466e-12, 9.39843833e-01, 3.33502777e-02, 2.68059261e-02,\n",
       "        4.20378142e-11, 2.58335107e-12, 1.20704592e-11],\n",
       "       [1.93021464e-04, 1.94431413e-02, 1.70563638e-01, 1.56048372e-01,\n",
       "        5.24936318e-01, 8.55502784e-02, 4.32653241e-02],\n",
       "       [7.35762207e-09, 7.97481298e-01, 1.23791702e-01, 7.87268803e-02,\n",
       "        1.13065575e-07, 1.59633551e-08, 4.33178968e-08],\n",
       "       [1.21552090e-04, 1.93382036e-02, 1.84329137e-01, 1.61170825e-01,\n",
       "        5.14148295e-01, 8.00950974e-02, 4.07967791e-02],\n",
       "       [3.24197515e-07, 1.85210118e-03, 6.28037229e-02, 1.91561803e-01,\n",
       "        7.31339931e-01, 1.00414343e-02, 2.40070443e-03],\n",
       "       [3.93086848e-11, 8.90224066e-04, 4.41825204e-02, 9.07770574e-01,\n",
       "        4.71339300e-02, 2.01941675e-05, 2.57959073e-06],\n",
       "       [7.20980548e-18, 4.08846796e-01, 3.29371616e-02, 5.58216095e-01,\n",
       "        1.43698768e-12, 3.67644672e-16, 6.24400184e-16],\n",
       "       [4.14733449e-03, 4.69628870e-02, 2.00967669e-01, 1.09668307e-01,\n",
       "        3.50340933e-01, 1.69001922e-01, 1.18910953e-01],\n",
       "       [1.33302024e-06, 1.16294599e-03, 3.49005200e-02, 9.89881903e-02,\n",
       "        8.42230916e-01, 1.82366204e-02, 4.47947904e-03],\n",
       "       [4.57991955e-05, 2.98636317e-01, 4.09163982e-01, 2.86721736e-01,\n",
       "        3.65745113e-03, 8.56919680e-04, 9.17906873e-04],\n",
       "       [2.88250950e-16, 9.37751174e-01, 2.59443652e-02, 3.63044627e-02,\n",
       "        1.92093750e-13, 1.73614236e-15, 9.22906855e-15],\n",
       "       [2.18409824e-08, 4.48100746e-01, 1.92043871e-01, 3.59850049e-01,\n",
       "        4.89027570e-06, 1.82499122e-07, 2.37757618e-07],\n",
       "       [2.42094116e-04, 3.15710217e-01, 4.47723240e-01, 2.18268752e-01,\n",
       "        9.15491022e-03, 4.16563265e-03, 4.73511359e-03],\n",
       "       [4.65020634e-07, 6.28212512e-01, 2.34883338e-01, 1.36885971e-01,\n",
       "        1.08982731e-05, 2.33684955e-06, 4.47370849e-06],\n",
       "       [2.88471259e-04, 1.30261211e-02, 1.22970633e-01, 1.13672130e-01,\n",
       "        5.95841110e-01, 1.02949530e-01, 5.12519628e-02],\n",
       "       [2.21683180e-17, 9.94922698e-01, 2.60912231e-03, 2.46811635e-03,\n",
       "        4.43450302e-17, 9.90109034e-19, 1.29620757e-17],\n",
       "       [4.72293529e-08, 7.58100152e-01, 1.53542846e-01, 8.83558914e-02,\n",
       "        6.31625312e-07, 1.22411009e-07, 2.99383316e-07],\n",
       "       [1.15635135e-18, 9.83051538e-01, 4.73777903e-03, 1.22106699e-02,\n",
       "        1.00044200e-16, 3.90676938e-19, 3.16957392e-18],\n",
       "       [3.66883911e-03, 6.26607910e-02, 2.44862720e-01, 1.29026458e-01,\n",
       "        2.98491061e-01, 1.50066212e-01, 1.11223958e-01],\n",
       "       [1.88731694e-13, 9.82006371e-01, 1.12055894e-02, 6.78795716e-03,\n",
       "        3.29696475e-13, 2.82918999e-14, 2.15321399e-13],\n",
       "       [1.09893697e-16, 9.90635812e-01, 5.10912528e-03, 4.25502518e-03,\n",
       "        7.26816208e-16, 1.86882616e-17, 1.99881895e-16],\n",
       "       [8.77251659e-05, 3.33086222e-01, 4.29974526e-01, 2.29468912e-01,\n",
       "        4.15937556e-03, 1.47910486e-03, 1.74421899e-03],\n",
       "       [6.56219470e-08, 5.84393144e-01, 2.05744386e-01, 2.09857345e-01,\n",
       "        4.13396674e-06, 3.68281491e-07, 6.20092976e-07],\n",
       "       [1.69546474e-10, 3.85717869e-01, 1.61421224e-01, 4.52860475e-01,\n",
       "        4.70460833e-07, 5.85139004e-09, 7.37293293e-09],\n",
       "       [9.81172707e-06, 1.17863230e-01, 4.50671107e-01, 4.02472228e-01,\n",
       "        2.42049880e-02, 2.75082770e-03, 2.02785339e-03],\n",
       "       [8.96842878e-11, 8.37588012e-01, 7.18480647e-02, 9.05639455e-02,\n",
       "        2.97414737e-09, 1.26620894e-10, 3.58763491e-10],\n",
       "       [9.89962177e-28, 9.99839664e-01, 3.28015994e-05, 1.27475214e-04,\n",
       "        1.23152512e-27, 8.82550626e-31, 4.70324400e-29],\n",
       "       [4.18743864e-03, 4.57545295e-02, 1.98185012e-01, 1.08989932e-01,\n",
       "        3.53977233e-01, 1.69900373e-01, 1.19005479e-01],\n",
       "       [3.34579800e-03, 8.64340290e-02, 2.98705846e-01, 1.50950849e-01,\n",
       "        2.36191154e-01, 1.25698924e-01, 9.86733884e-02],\n",
       "       [3.39320377e-11, 7.68159151e-01, 7.24624097e-02, 1.59378424e-01,\n",
       "        3.00246183e-09, 5.90543239e-11, 1.36750555e-10],\n",
       "       [2.29440378e-08, 8.00399363e-01, 1.28742203e-01, 7.08579421e-02,\n",
       "        2.38693474e-07, 4.79374691e-08, 1.28634753e-07],\n",
       "       [1.96598150e-04, 1.10242357e-02, 1.12702392e-01, 1.14999227e-01,\n",
       "        6.26293123e-01, 9.17542353e-02, 4.30301689e-02],\n",
       "       [1.43524533e-22, 9.99786198e-01, 1.21533456e-04, 9.22742911e-05,\n",
       "        1.47929106e-23, 2.49454606e-25, 1.13979388e-23],\n",
       "       [1.43752210e-08, 3.30996290e-02, 2.24460274e-01, 7.37815499e-01,\n",
       "        4.55756439e-03, 4.64459590e-05, 2.07073808e-05],\n",
       "       [3.84572166e-11, 9.09367621e-01, 5.01692370e-02, 4.04632129e-02,\n",
       "        4.43742404e-10, 3.19250529e-11, 1.24212224e-10],\n",
       "       [2.08824277e-13, 9.80437100e-01, 1.21024931e-02, 7.46041164e-03,\n",
       "        4.37700494e-13, 3.60201100e-14, 2.65748794e-13],\n",
       "       [5.89475829e-18, 5.14550745e-01, 2.66608726e-02, 4.58788395e-01,\n",
       "        4.00225914e-13, 1.10766518e-16, 2.15851841e-16],\n",
       "       [7.59510094e-11, 9.13656771e-01, 5.14948219e-02, 3.48484069e-02,\n",
       "        6.16489138e-10, 5.93971677e-11, 2.39709141e-10],\n",
       "       [1.74818222e-08, 8.13850820e-01, 1.19998008e-01, 6.61508963e-02,\n",
       "        1.59773720e-07, 3.18757891e-08, 8.83797711e-08],\n",
       "       [2.11108691e-12, 9.73482847e-01, 1.70815885e-02, 9.43550747e-03,\n",
       "        4.02946643e-12, 4.74261038e-13, 3.05248014e-12],\n",
       "       [2.12514797e-10, 1.84069738e-01, 2.38158345e-01, 5.77763736e-01,\n",
       "        8.00018097e-06, 8.74531594e-08, 8.35794793e-08],\n",
       "       [3.47735778e-08, 6.34330630e-01, 1.86007857e-01, 1.79659307e-01,\n",
       "        1.76885817e-06, 1.60685616e-07, 2.96147618e-07],\n",
       "       [3.91263938e-10, 8.27515244e-01, 8.80822316e-02, 8.44025239e-02,\n",
       "        1.04439639e-08, 6.95224156e-10, 1.96204830e-09],\n",
       "       [1.61901515e-19, 1.13746244e-02, 9.39048920e-03, 9.79234934e-01,\n",
       "        8.14205925e-11, 1.17366844e-15, 5.18635362e-16]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1=pd.DataFrame(y_pred.max(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester=np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.DataFrame(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_scale=[1,10,100,300,1000,5000]\n",
    "def un_scaler(y):\n",
    "    if y == 1:\n",
    "        y1='1 acre or less'\n",
    "    elif y == 2:\n",
    "        y1 = 'more than one acre, but less than 10 acres'\n",
    "    elif y == 3:\n",
    "        y1 = '10 acres or more, but less than 100 acres'\n",
    "    elif y == 4:\n",
    "        y1 = '100 acres or more, but less than 300 acres'\n",
    "    elif y == 5:\n",
    "        y1 = '300 acres or more, but less than 1,000 acres'\n",
    "    elif y == 6:\n",
    "        y1 = '1,000 acres or more, but less than 5,000 acres'\n",
    "    return y1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nClassification\\n#Convert to Acres then Classify Size\\nClass 1.A - one acre or less;\\nClass 2.B - more than one acre, but less than 10 acres;\\nClass 3.C - 10 acres or more, but less than 100 acres;\\nClass 4.D - 100 acres or more, but less than 300 acres;\\nClass 5.E - 300 acres or more, but less than 1,000 acres;\\nClass 6.F - 1,000 acres or more, but less than 5,000 acres;\\n'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Classification\n",
    "#Convert to Acres then Classify Size\n",
    "Class 1.A - one acre or less;\n",
    "Class 2.B - more than one acre, but less than 10 acres;\n",
    "Class 3.C - 10 acres or more, but less than 100 acres;\n",
    "Class 4.D - 100 acres or more, but less than 300 acres;\n",
    "Class 5.E - 300 acres or more, but less than 1,000 acres;\n",
    "Class 6.F - 1,000 acres or more, but less than 5,000 acres;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2=output[0].apply(un_scaler)\n",
    "o2=pd.DataFrame(o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1.columns=[\"percentage\"]\n",
    "o2.columns=[\"desc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.524936</td>\n",
       "      <td>100 acres or more, but less than 300 acres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.492578</td>\n",
       "      <td>10 acres or more, but less than 100 acres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.991948</td>\n",
       "      <td>1 acre or less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.694616</td>\n",
       "      <td>10 acres or more, but less than 100 acres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.759692</td>\n",
       "      <td>1 acre or less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.973483</td>\n",
       "      <td>1 acre or less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.577764</td>\n",
       "      <td>10 acres or more, but less than 100 acres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.634331</td>\n",
       "      <td>1 acre or less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.827515</td>\n",
       "      <td>1 acre or less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.979235</td>\n",
       "      <td>10 acres or more, but less than 100 acres</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     percentage                                        desc\n",
       "0      0.524936  100 acres or more, but less than 300 acres\n",
       "1      0.492578   10 acres or more, but less than 100 acres\n",
       "2      0.991948                              1 acre or less\n",
       "3      0.694616   10 acres or more, but less than 100 acres\n",
       "4      0.759692                              1 acre or less\n",
       "..          ...                                         ...\n",
       "99     0.973483                              1 acre or less\n",
       "100    0.577764   10 acres or more, but less than 100 acres\n",
       "101    0.634331                              1 acre or less\n",
       "102    0.827515                              1 acre or less\n",
       "103    0.979235   10 acres or more, but less than 100 acres\n",
       "\n",
       "[104 rows x 2 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.concat([o1,o2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.722958    209\n",
       "45.974956    104\n",
       "12.767304     80\n",
       "25.566087     15\n",
       "20.377391      3\n",
       "44.591304      2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"ANN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
